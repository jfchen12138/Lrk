{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3 Darcy inverse interface coefficient identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package not found.\n",
      "Please install Plotly for showing mesh and solutions.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from libs import *\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mLoading piececonst_r421_N1024_smooth1.mat: start at 1701396056.22;\u001b[0m\n",
      "\u001b[92mLOCAL RAM USAGE AT START: 0.34 GB\u001b[0m\n",
      "\u001b[94mLoading piececonst_r421_N1024_smooth1.mat: done at 1701396073.10 (16.880470 secs elapsed);\u001b[0m\n",
      "\u001b[92mLOCAL RAM USAGE AT END: 1.87GB (+1.53GB)\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mLoading piececonst_r421_N1024_smooth2.mat: start at 1701396077.34;\u001b[0m\n",
      "\u001b[92mLOCAL RAM USAGE AT START: 0.69 GB\u001b[0m\n",
      "\u001b[94mLoading piececonst_r421_N1024_smooth2.mat: done at 1701396094.48 (17.140016 secs elapsed);\u001b[0m\n",
      "\u001b[92mLOCAL RAM USAGE AT END: 2.23GB (+1.53GB)\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noise = 1e-2\n",
    "subsample_nodes = 3\n",
    "subsample_attn = 6\n",
    "train_path = os.path.join(DATA_PATH, 'piececonst_r421_N1024_smooth1.mat')\n",
    "test_path = os.path.join(DATA_PATH, 'piececonst_r421_N1024_smooth2.mat')\n",
    "train_dataset = DarcyDataset(data_path=train_path,\n",
    "                             subsample_attn=subsample_attn,\n",
    "                             subsample_nodes=subsample_nodes,\n",
    "                             subsample_inverse=subsample_attn,\n",
    "                             subsample_method='average',\n",
    "                             inverse_problem=True,\n",
    "                             return_boundary=True,\n",
    "                             return_edge=False,\n",
    "                             train_data=True,\n",
    "                             noise=noise,\n",
    "                             train_len=1)\n",
    "\n",
    "valid_dataset = DarcyDataset(data_path=test_path,\n",
    "                             normalizer_x=train_dataset.normalizer_x,\n",
    "                             subsample_attn=subsample_attn,\n",
    "                             subsample_nodes=subsample_nodes,\n",
    "                             subsample_inverse=subsample_attn,\n",
    "                             subsample_method='average',\n",
    "                             inverse_problem=True,\n",
    "                             return_boundary=True,\n",
    "                             return_edge=False,\n",
    "                             train_data=False,\n",
    "                             noise=noise,\n",
    "                             valid_len=100)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, drop_last=False,\n",
    "                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model's validation metric: {'metric': 0.0372577290982008}\n"
     ]
    }
   ],
   "source": [
    "n_grid = int(((421 - 1)/subsample_nodes) + 1)\n",
    "n_grid_c = int(((421 - 1)/subsample_attn) + 1)\n",
    "h = 1/n_grid_c\n",
    "metric_func = WeightedL2Loss2d(regularizer=False, h=h)\n",
    "\n",
    "model = torch.load(os.path.join(MODEL_PATH, 'darcy_inv_141_6ft_320d_qkv_4h_1.0e-02_2023-11-23.pt'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "val_metric = validate_epoch_darcy(model, metric_func, valid_loader, device)\n",
    "print(f\"\\nModel's validation metric: {val_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galerkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise = 1e-2\n",
    "# subsample_nodes = 3\n",
    "# subsample_attn = 6\n",
    "# train_path = os.path.join(DATA_PATH, 'piececonst_r421_N1024_smooth1.mat')\n",
    "# test_path = os.path.join(DATA_PATH, 'piececonst_r421_N1024_smooth2.mat')\n",
    "# train_dataset = DarcyDataset(data_path=train_path,\n",
    "#                              subsample_attn=subsample_attn,\n",
    "#                              subsample_nodes=subsample_nodes,\n",
    "#                              subsample_inverse=subsample_attn,\n",
    "#                              subsample_method='average',\n",
    "#                              inverse_problem=True,\n",
    "#                              return_boundary=True,\n",
    "#                              return_edge=False,\n",
    "#                              train_data=True,\n",
    "#                              noise=noise,\n",
    "#                              train_len=1)\n",
    "\n",
    "# valid_dataset = DarcyDataset(data_path=test_path,\n",
    "#                              normalizer_x=train_dataset.normalizer_x,\n",
    "#                              subsample_attn=subsample_attn,\n",
    "#                              subsample_nodes=subsample_nodes,\n",
    "#                              subsample_inverse=subsample_attn,\n",
    "#                              subsample_method='average',\n",
    "#                              inverse_problem=True,\n",
    "#                              return_boundary=True,\n",
    "#                              return_edge=False,\n",
    "#                              train_data=False,\n",
    "#                              noise=noise,\n",
    "#                              valid_len=100)\n",
    "\n",
    "# valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, drop_last=False,\n",
    "#                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model's validation metric: {'metric': 0.036250049024820326}\n"
     ]
    }
   ],
   "source": [
    "n_grid = int(((421 - 1)/subsample_nodes) + 1)\n",
    "n_grid_c = int(((421 - 1)/subsample_attn) + 1)\n",
    "h = 1/n_grid_c\n",
    "metric_func = WeightedL2Loss2d(regularizer=False, h=h)\n",
    "\n",
    "model = torch.load(os.path.join(MODEL_PATH, 'darcy_inv_141_6gt_320d_qkv_4h_1.0e-02_2023-11-23.pt'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "val_metric = validate_epoch_darcy(model, metric_func, valid_loader, device)\n",
    "print(f\"\\nModel's validation metric: {val_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Lrk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise = 1e-2\n",
    "# subsample_nodes = 3\n",
    "# subsample_attn = 6\n",
    "# train_path = os.path.join(DATA_PATH, 'piececonst_r421_N1024_smooth1.mat')\n",
    "# test_path = os.path.join(DATA_PATH, 'piececonst_r421_N1024_smooth2.mat')\n",
    "# train_dataset = DarcyDataset(data_path=train_path,\n",
    "#                              subsample_attn=subsample_attn,\n",
    "#                              subsample_nodes=subsample_nodes,\n",
    "#                              subsample_inverse=subsample_attn,\n",
    "#                              subsample_method='average',\n",
    "#                              inverse_problem=True,\n",
    "#                              return_boundary=True,\n",
    "#                              return_edge=False,\n",
    "#                              train_data=True,\n",
    "#                              noise=noise,\n",
    "#                              train_len=1)\n",
    "\n",
    "# valid_dataset = DarcyDataset(data_path=test_path,\n",
    "#                              normalizer_x=train_dataset.normalizer_x,\n",
    "#                              subsample_attn=subsample_attn,\n",
    "#                              subsample_nodes=subsample_nodes,\n",
    "#                              subsample_inverse=subsample_attn,\n",
    "#                              subsample_method='average',\n",
    "#                              inverse_problem=True,\n",
    "#                              return_boundary=True,\n",
    "#                              return_edge=False,\n",
    "#                              train_data=False,\n",
    "#                              noise=noise,\n",
    "#                              valid_len=100)\n",
    "\n",
    "# valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, drop_last=False,\n",
    "#                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "\n",
      "Model's validation metric: {'metric': 0.04127108350396156}\n"
     ]
    }
   ],
   "source": [
    "n_grid = int(((421 - 1)/subsample_nodes) + 1)\n",
    "n_grid_c = int(((421 - 1)/subsample_attn) + 1)\n",
    "h = 1/n_grid_c\n",
    "metric_func = WeightedL2Loss2d(regularizer=False, h=h)\n",
    "\n",
    "model = torch.load(os.path.join(MODEL_PATH, 'darcy_inv_141_6Lt_320d_qkv_4h_1.0e-02_2023-11-23.pt'))\n",
    "model.to(device)\n",
    "print(len(model.v))\n",
    "model.eval()\n",
    "val_metric = validate_epoch_darcy(model, metric_func, valid_loader, device)\n",
    "print(f\"\\nModel's validation metric: {val_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95502389cfcf018ee4ea9f0d83bae034c520ccac7d682848f1b351d0b7f2112c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "metadata": {
   "interpreter": {
    "hash": "95502389cfcf018ee4ea9f0d83bae034c520ccac7d682848f1b351d0b7f2112c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
