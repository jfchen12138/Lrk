{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2 Darcy interface flow evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package not found.\n",
      "Please install Plotly for showing mesh and solutions.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from libs import *\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mLoading piececonst_r421_N1024_smooth1.mat: start at 1701396164.21;\u001b[0m\n",
      "\u001b[92mLOCAL RAM USAGE AT START: 0.34 GB\u001b[0m\n",
      "\u001b[94mLoading piececonst_r421_N1024_smooth1.mat: done at 1701396180.98 (16.761958 secs elapsed);\u001b[0m\n",
      "\u001b[92mLOCAL RAM USAGE AT END: 1.88GB (+1.54GB)\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mLoading piececonst_r421_N1024_smooth2.mat: start at 1701396182.34;\u001b[0m\n",
      "\u001b[92mLOCAL RAM USAGE AT START: 2.34 GB\u001b[0m\n",
      "\u001b[94mLoading piececonst_r421_N1024_smooth2.mat: done at 1701396199.29 (16.946509 secs elapsed);\u001b[0m\n",
      "\u001b[92mLOCAL RAM USAGE AT END: 3.86GB (+1.52GB)\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subsample_nodes = 3\n",
    "subsample_attn = 6\n",
    "train_path = os.path.join(DATA_PATH, 'piececonst_r421_N1024_smooth1.mat')\n",
    "test_path = os.path.join(DATA_PATH, 'piececonst_r421_N1024_smooth2.mat')\n",
    "train_dataset = DarcyDataset(data_path=train_path,\n",
    "                                subsample_attn=subsample_attn,\n",
    "                                subsample_nodes=subsample_nodes,\n",
    "                                train_data=True,\n",
    "                                train_len=1024,)\n",
    "\n",
    "valid_dataset = DarcyDataset(data_path=test_path,\n",
    "                                normalizer_x=train_dataset.normalizer_x,\n",
    "                                subsample_attn=subsample_attn,\n",
    "                                subsample_nodes=subsample_nodes,\n",
    "                                train_data=False,\n",
    "                                valid_len=100)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False,\n",
    "                            drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model's validation metric: {'metric': 0.008343311911448836}\n"
     ]
    }
   ],
   "source": [
    "n_grid = int(((421 - 1)/subsample_nodes) + 1)\n",
    "n_grid_c = int(((421 - 1)/subsample_attn) + 1)\n",
    "h = 1/n_grid\n",
    "metric_func = WeightedL2Loss2d(regularizer=False, h=h)\n",
    "model = torch.load(os.path.join(MODEL_PATH, 'darcy_141_6ft_256d_qkv_32f_2023-11-20.pt'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "val_metric = validate_epoch_darcy(model, metric_func, valid_loader, device)\n",
    "print(f\"\\nModel's validation metric: {val_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galerkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample_nodes = 3\n",
    "# subsample_attn = 6\n",
    "# train_path = os.path.join(DATA_PATH, 'piececonst_r421_N1024_smooth1.mat')\n",
    "# test_path = os.path.join(DATA_PATH, 'piececonst_r421_N1024_smooth2.mat')\n",
    "# train_dataset = DarcyDataset(data_path=train_path,\n",
    "#                                 subsample_attn=subsample_attn,\n",
    "#                                 subsample_nodes=subsample_nodes,\n",
    "#                                 train_data=True,\n",
    "#                                 train_len=1024,)\n",
    "\n",
    "# valid_dataset = DarcyDataset(data_path=test_path,\n",
    "#                                 normalizer_x=train_dataset.normalizer_x,\n",
    "#                                 subsample_attn=subsample_attn,\n",
    "#                                 subsample_nodes=subsample_nodes,\n",
    "#                                 train_data=False,\n",
    "#                                 valid_len=100)\n",
    "# valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False,\n",
    "#                             drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model's validation metric: {'metric': 0.008848846592009067}\n"
     ]
    }
   ],
   "source": [
    "n_grid = int(((421 - 1)/subsample_nodes) + 1)\n",
    "n_grid_c = int(((421 - 1)/subsample_attn) + 1)\n",
    "h = 1/n_grid\n",
    "metric_func = WeightedL2Loss2d(regularizer=False, h=h)\n",
    "model = torch.load(os.path.join(MODEL_PATH, 'darcy_141_6gt_256d_qkv_32f_2023-11-20.pt'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "val_metric = validate_epoch_darcy(model, metric_func, valid_loader, device)\n",
    "print(f\"\\nModel's validation metric: {val_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lrk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample_nodes = 3\n",
    "# subsample_attn = 6\n",
    "# train_path = os.path.join(DATA_PATH, 'piececonst_r421_N1024_smooth1.mat')\n",
    "# test_path = os.path.join(DATA_PATH, 'piececonst_r421_N1024_smooth2.mat')\n",
    "# train_dataset = DarcyDataset(data_path=train_path,\n",
    "#                                 subsample_attn=subsample_attn,\n",
    "#                                 subsample_nodes=subsample_nodes,\n",
    "#                                 train_data=True,\n",
    "#                                 train_len=1024,)\n",
    "\n",
    "# valid_dataset = DarcyDataset(data_path=test_path,\n",
    "#                                 normalizer_x=train_dataset.normalizer_x,\n",
    "#                                 subsample_attn=subsample_attn,\n",
    "#                                 subsample_nodes=subsample_nodes,\n",
    "#                                 train_data=False,\n",
    "#                                 valid_len=100)\n",
    "# valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False,\n",
    "#                             drop_last=False, pin_memory=True)\n",
    "\n",
    "# n_grid = int(((421 - 1)/subsample_nodes) + 1)\n",
    "# n_grid_c = int(((421 - 1)/subsample_attn) + 1)\n",
    "# downsample, upsample = DarcyDataset.get_scaler_sizes(n_grid, n_grid_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "\n",
      "Model's validation metric: {'metric': 0.008303205585107207}\n"
     ]
    }
   ],
   "source": [
    "n_grid = int(((421 - 1)/subsample_nodes) + 1)\n",
    "n_grid_c = int(((421 - 1)/subsample_attn) + 1)\n",
    "h = 1/n_grid\n",
    "metric_func = WeightedL2Loss2d(regularizer=False, h=h)\n",
    "model = torch.load(os.path.join(MODEL_PATH, 'darcy_141_6Lt_256d_qkv_32f_2023-11-20.pt'))\n",
    "model.to(device)\n",
    "print(len(model.v))\n",
    "model.eval()\n",
    "val_metric = validate_epoch_darcy(model, metric_func, valid_loader, device)\n",
    "print(f\"\\nModel's validation metric: {val_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = next(iter(valid_loader))\n",
    "# a = sample['node']\n",
    "# pos = sample['pos']\n",
    "# u = sample['target']\n",
    "# grid = sample['grid']\n",
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     out_ = model(a.to(device), None, pos.to(device), grid.to(device))\n",
    "#     preds = out_['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# z = preds[i, ..., 0].cpu().numpy()\n",
    "# z_true = u[i, ..., 0].cpu().numpy()\n",
    "# _ = showcontour(z, width=300, height=300,)\n",
    "# _ = showcontour(z_true, width=300, height=300,)\n",
    "# print(\"Relative error: \", np.linalg.norm(z-z_true)/np.linalg.norm(z_true), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 1\n",
    "# z = preds[i, ..., 0].cpu().numpy()\n",
    "# z_true = u[i, ..., 0].cpu().numpy()\n",
    "# _ = showcontour(z, width=300, height=300,)\n",
    "# _ = showcontour(z_true, width=300, height=300,)\n",
    "# print(\"Relative error: \", np.linalg.norm(z-z_true)/np.linalg.norm(z_true), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 2\n",
    "# z = preds[i, ..., 0].cpu().numpy()\n",
    "# z_true = u[i, ..., 0].cpu().numpy()\n",
    "# _ = showcontour(z, width=300, height=300,)\n",
    "# _ = showcontour(z_true, width=300, height=300,)\n",
    "# print(\"Relative error: \", np.linalg.norm(z-z_true)/np.linalg.norm(z_true), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 3\n",
    "# z = preds[i, ..., 0].cpu().numpy()\n",
    "# z_true = u[i, ..., 0].cpu().numpy()\n",
    "# _ = showcontour(z, width=300, height=300,)\n",
    "# _ = showcontour(z_true, width=300, height=300,)\n",
    "# print(\"Relative error: \", np.linalg.norm(z-z_true)/np.linalg.norm(z_true), '\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95502389cfcf018ee4ea9f0d83bae034c520ccac7d682848f1b351d0b7f2112c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "metadata": {
   "interpreter": {
    "hash": "95502389cfcf018ee4ea9f0d83bae034c520ccac7d682848f1b351d0b7f2112c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
